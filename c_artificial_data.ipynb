{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Missing Values\n",
    "\n",
    "# Fix Missing Values\n",
    "- sklearn data imputer\n",
    "    - vary strategy parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import shutil, os, io\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mylib.ml_helpers import *\n",
    "\n",
    "DATA_ROOT = 'data/forest-cover-type'\n",
    "DATA_TRAIN = DATA_ROOT+'/train.csv'\n",
    "DATA_TEST = DATA_ROOT+'/test.csv'\n",
    "\n",
    "df_train = pd.read_csv(DATA_TRAIN)\n",
    "\n",
    "features_numerical = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
    "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "       'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "features_categorical = ['Wilderness_Area1',\n",
    "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
    "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
    "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
    "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
    "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
    "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
    "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
    "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
    "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
    "       'Soil_Type39', 'Soil_Type40']\n",
    "\n",
    "label = ['Cover_Type']\n",
    "\n",
    "remove_columns = ['Id']\n",
    "\n",
    "remove_constant_features = get_constant_features(df_train)\n",
    "\n",
    "remove_columns.extend(remove_constant_features)\n",
    "\n",
    "df_train.drop(remove_columns, axis=1, inplace=True)\n",
    "features_categorical = list(set(features_categorical) - set(remove_constant_features))\n",
    "\n",
    "features = df_train.drop(label, axis=1)\n",
    "labels = df_train[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C (1)\n",
    "- a\n",
    "- b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             1550\n",
       "Aspect                                1466\n",
       "Slope                                 1446\n",
       "Horizontal_Distance_To_Hydrology      1464\n",
       "Vertical_Distance_To_Hydrology        1514\n",
       "Horizontal_Distance_To_Roadways       1457\n",
       "Hillshade_9am                         1499\n",
       "Hillshade_Noon                        1582\n",
       "Hillshade_3pm                         1503\n",
       "Horizontal_Distance_To_Fire_Points    1498\n",
       "Wilderness_Area1                      1514\n",
       "Wilderness_Area2                      1562\n",
       "Wilderness_Area3                      1529\n",
       "Wilderness_Area4                      1552\n",
       "Soil_Type1                            1507\n",
       "Soil_Type2                            1532\n",
       "Soil_Type3                            1546\n",
       "Soil_Type4                            1525\n",
       "Soil_Type5                            1486\n",
       "Soil_Type6                            1471\n",
       "Soil_Type8                            1552\n",
       "Soil_Type9                            1531\n",
       "Soil_Type10                           1481\n",
       "Soil_Type11                           1502\n",
       "Soil_Type12                           1493\n",
       "Soil_Type13                           1501\n",
       "Soil_Type14                           1589\n",
       "Soil_Type16                           1473\n",
       "Soil_Type17                           1533\n",
       "Soil_Type18                           1489\n",
       "Soil_Type19                           1501\n",
       "Soil_Type20                           1526\n",
       "Soil_Type21                           1569\n",
       "Soil_Type22                           1531\n",
       "Soil_Type23                           1523\n",
       "Soil_Type24                           1501\n",
       "Soil_Type25                           1588\n",
       "Soil_Type26                           1543\n",
       "Soil_Type27                           1548\n",
       "Soil_Type28                           1463\n",
       "Soil_Type29                           1548\n",
       "Soil_Type30                           1535\n",
       "Soil_Type31                           1497\n",
       "Soil_Type32                           1508\n",
       "Soil_Type33                           1479\n",
       "Soil_Type34                           1507\n",
       "Soil_Type35                           1529\n",
       "Soil_Type36                           1460\n",
       "Soil_Type37                           1508\n",
       "Soil_Type38                           1468\n",
       "Soil_Type39                           1470\n",
       "Soil_Type40                           1475\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''1a'''\n",
    "def get_random_1a(features, p=0.1):\n",
    "    c = int(features.shape[0]*features.shape[1]*p)\n",
    "    A = np.ones(features.shape)\n",
    "\n",
    "    mask = np.zeros(features.shape[0]*features.shape[1], dtype=bool)\n",
    "    mask[:c] = True\n",
    "    np.random.shuffle(mask)\n",
    "    mask = mask.reshape(features.shape[0], features.shape[1])\n",
    "\n",
    "    A[mask] = np.nan\n",
    "    df_missing_values = pd.DataFrame(A, columns=list(features.columns))\n",
    "    df_missing_values = features[~df_missing_values.isna()]\n",
    "    return df_missing_values\n",
    "\n",
    "rnd_1a = get_random_1a(features, 0.1)\n",
    "rnd_1a.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             1512\n",
       "Aspect                                1512\n",
       "Slope                                 1512\n",
       "Horizontal_Distance_To_Hydrology      1512\n",
       "Vertical_Distance_To_Hydrology        1512\n",
       "Horizontal_Distance_To_Roadways       1512\n",
       "Hillshade_9am                         1512\n",
       "Hillshade_Noon                        1512\n",
       "Hillshade_3pm                         1512\n",
       "Horizontal_Distance_To_Fire_Points    1512\n",
       "Wilderness_Area1                      1512\n",
       "Wilderness_Area2                      1512\n",
       "Wilderness_Area3                      1512\n",
       "Wilderness_Area4                      1512\n",
       "Soil_Type1                            1512\n",
       "Soil_Type2                            1512\n",
       "Soil_Type3                            1512\n",
       "Soil_Type4                            1512\n",
       "Soil_Type5                            1512\n",
       "Soil_Type6                            1512\n",
       "Soil_Type8                            1512\n",
       "Soil_Type9                            1512\n",
       "Soil_Type10                           1512\n",
       "Soil_Type11                           1512\n",
       "Soil_Type12                           1512\n",
       "Soil_Type13                           1512\n",
       "Soil_Type14                           1512\n",
       "Soil_Type16                           1512\n",
       "Soil_Type17                           1512\n",
       "Soil_Type18                           1512\n",
       "Soil_Type19                           1512\n",
       "Soil_Type20                           1512\n",
       "Soil_Type21                           1512\n",
       "Soil_Type22                           1512\n",
       "Soil_Type23                           1512\n",
       "Soil_Type24                           1512\n",
       "Soil_Type25                           1512\n",
       "Soil_Type26                           1512\n",
       "Soil_Type27                           1512\n",
       "Soil_Type28                           1512\n",
       "Soil_Type29                           1512\n",
       "Soil_Type30                           1512\n",
       "Soil_Type31                           1512\n",
       "Soil_Type32                           1512\n",
       "Soil_Type33                           1512\n",
       "Soil_Type34                           1512\n",
       "Soil_Type35                           1512\n",
       "Soil_Type36                           1512\n",
       "Soil_Type37                           1512\n",
       "Soil_Type38                           1512\n",
       "Soil_Type39                           1512\n",
       "Soil_Type40                           1512\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''1b'''\n",
    "def get_random_1b(features, p=0.1):\n",
    "    c = int(features.shape[0]*p)\n",
    "    n_rows = features.shape[0]\n",
    "    m_cols = 1\n",
    "    empty_arr = []\n",
    "\n",
    "    for i in range(0, features.shape[1]):\n",
    "        col = np.ones((n_rows, m_cols))\n",
    "\n",
    "        mask = np.zeros(n_rows * m_cols, dtype=bool)\n",
    "        mask[:c] = True\n",
    "\n",
    "        np.random.shuffle(mask)\n",
    "\n",
    "        mask = mask.reshape(col.shape[0], col.shape[1])\n",
    "        col[mask] = np.nan\n",
    "\n",
    "        empty_arr.append(list(col.flatten()))\n",
    "\n",
    "    df_artificial = pd.DataFrame(empty_arr).T\n",
    "    df_artificial.columns = features.columns\n",
    "    df_artificial = features[~df_artificial.isna()]\n",
    "    return df_artificial\n",
    "\n",
    "rnd_1b = get_random_1b(features, 0.1)\n",
    "rnd_1b.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C (2)\n",
    "- a\n",
    "- b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12096, 52) (3024, 52) (12096,) (3024,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "seed = 42\n",
    "features_train = features.values\n",
    "labels_train = labels.values.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train, labels_train, test_size=0.20,  random_state=seed)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>information_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevation</td>\n",
       "      <td>1.02174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wilderness_Area4</td>\n",
       "      <td>0.427716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horizontal_Distance_To_Roadways</td>\n",
       "      <td>0.313187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Horizontal_Distance_To_Fire_Points</td>\n",
       "      <td>0.196566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wilderness_Area1</td>\n",
       "      <td>0.172483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature information_gain\n",
       "0                            Elevation          1.02174\n",
       "13                    Wilderness_Area4         0.427716\n",
       "5      Horizontal_Distance_To_Roadways         0.313187\n",
       "9   Horizontal_Distance_To_Fire_Points         0.196566\n",
       "10                    Wilderness_Area1         0.172483"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>information_gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Soil_Type26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Soil_Type25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Soil_Type34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Soil_Type35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Soil_Type9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature information_gain\n",
       "37  Soil_Type26                0\n",
       "36  Soil_Type25                0\n",
       "45  Soil_Type34                0\n",
       "46  Soil_Type35                0\n",
       "21   Soil_Type9                0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "feature_mutual_informaion = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "information_gain = pd.DataFrame([features.columns, feature_mutual_informaion]).T\n",
    "information_gain.columns = ['feature','information_gain']\n",
    "information_gain.sort_values(by='information_gain', ascending=False, inplace=True)\n",
    "display(information_gain.head(), information_gain.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                           12096\n",
       "Aspect                                  0\n",
       "Slope                                   0\n",
       "Horizontal_Distance_To_Hydrology        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Elevation                           3024\n",
       "Aspect                                 0\n",
       "Slope                                  0\n",
       "Horizontal_Distance_To_Hydrology       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Soil_Type26    12096\n",
       "Soil_Type27        0\n",
       "Soil_Type28        0\n",
       "Soil_Type29        0\n",
       "Soil_Type30        0\n",
       "Soil_Type31        0\n",
       "Soil_Type32        0\n",
       "Soil_Type33        0\n",
       "Soil_Type34        0\n",
       "Soil_Type35        0\n",
       "Soil_Type36        0\n",
       "Soil_Type37        0\n",
       "Soil_Type38        0\n",
       "Soil_Type39        0\n",
       "Soil_Type40        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Soil_Type26    3024\n",
       "Soil_Type27       0\n",
       "Soil_Type28       0\n",
       "Soil_Type29       0\n",
       "Soil_Type30       0\n",
       "Soil_Type31       0\n",
       "Soil_Type32       0\n",
       "Soil_Type33       0\n",
       "Soil_Type34       0\n",
       "Soil_Type35       0\n",
       "Soil_Type36       0\n",
       "Soil_Type37       0\n",
       "Soil_Type38       0\n",
       "Soil_Type39       0\n",
       "Soil_Type40       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''2a add nan value to only one feature'''\n",
    "def get_random_2a(data, selected_col, p):\n",
    "    c = int(data.shape[0]*p)\n",
    "    n_rows = data.shape[0]\n",
    "    m_cols = 1\n",
    "\n",
    "    col = np.ones((n_rows, m_cols))\n",
    "\n",
    "    mask = np.zeros(n_rows * m_cols, dtype=bool)\n",
    "    mask[:c] = True\n",
    "\n",
    "    np.random.shuffle(mask)\n",
    "\n",
    "    mask = mask.reshape(col.shape[0], col.shape[1])\n",
    "    col[mask] = np.nan\n",
    "\n",
    "    df_artificial = pd.DataFrame(col, columns=selected_col)\n",
    "    df_artificial = data[selected_col][~df_artificial.isna()]\n",
    "    data[selected_col] = df_artificial\n",
    "    return data\n",
    "\n",
    "\n",
    "high_ig = ['Elevation'] \n",
    "features_copy = features.copy()\n",
    "rnd_2a_hi_hi = get_random_2a(features_copy, high_ig, p=0.8)\n",
    "features_copy = features.copy()\n",
    "rnd_2a_hi_lo = get_random_2a(features_copy, high_ig, p=0.2)\n",
    "\n",
    "low_ig = ['Soil_Type26']\n",
    "features_copy = features.copy()\n",
    "rnd_2a_lo_hi = get_random_2a(features_copy, low_ig, p=0.8)\n",
    "features_copy = features.copy()\n",
    "rnd_2a_lo_lo = get_random_2a(features_copy, low_ig, p=0.2)\n",
    "\n",
    "display(rnd_2a_hi_hi.isna().sum().head(4) , rnd_2a_hi_lo.isna().sum().head(4))\n",
    "display(rnd_2a_lo_hi.isna().sum().tail(15), rnd_2a_lo_lo.isna().sum().tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2b add small/lagre fraction nan values to only ALL features'''\n",
    "small = 0.2\n",
    "large = 0.8\n",
    "\n",
    "\n",
    "features_copy = features.copy()\n",
    "rnd_2b_small = get_random_1b(features_copy, small)\n",
    "\n",
    "features_copy = features.copy()\n",
    "rnd_2b_large = get_random_1b(features_copy, large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                           3024\n",
       "Aspect                              3024\n",
       "Slope                               3024\n",
       "Horizontal_Distance_To_Hydrology    3024\n",
       "Vertical_Distance_To_Hydrology      3024\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Elevation                           12096\n",
       "Aspect                              12096\n",
       "Slope                               12096\n",
       "Horizontal_Distance_To_Hydrology    12096\n",
       "Vertical_Distance_To_Hydrology      12096\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rnd_2b_small.isna().sum().head(), rnd_2b_large.isna().sum().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C (3)\n",
    "Implement different strategies to deal with these missing values and describe their implementation, by\n",
    "- a. ignoring the respective attributes completely in the dataset\n",
    "- b. replacing the missing attribute values by the mean/median value of that attribute in the entire dataset\n",
    "- c. replacing the missing attribute by the mean / median value of that attribute in the respective class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "> one attribute (2a)\n",
    "rnd_2a_hi_lo\n",
    "rnd_2a_hi_hi\n",
    "rnd_2a_lo_lo\n",
    "rnd_2a_lo_hi\n",
    "\n",
    "> all attributes (2b)\n",
    "rnd_2b_small\n",
    "rnd_2b_large\n",
    "'''\n",
    "\n",
    "all_datasets_names = ['rnd_2a_hi_lo',\n",
    "                        'rnd_2a_hi_hi',\n",
    "                        'rnd_2a_lo_lo',\n",
    "                        'rnd_2a_lo_hi',\n",
    "                        'rnd_2b_small',\n",
    "                        'rnd_2b_large']\n",
    "\n",
    "all_datasets = [rnd_2a_hi_lo.copy(), rnd_2a_hi_hi.copy(), rnd_2a_lo_lo.copy(), rnd_2a_lo_hi.copy(), rnd_2b_small.copy(), rnd_2b_large.copy()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a.)\n",
      "shape after ignoring attribute(s) containing nan values..\n",
      "dataset: rnd_2a_hi_lo (15120, 51)\n",
      "dataset: rnd_2a_hi_hi (15120, 51)\n",
      "dataset: rnd_2a_lo_lo (15120, 51)\n",
      "dataset: rnd_2a_lo_hi (15120, 51)\n",
      "dataset: rnd_2b_small (15120, 0)\n",
      "dataset: rnd_2b_large (15120, 0)\n"
     ]
    }
   ],
   "source": [
    "def ignore_attribute(df):\n",
    "    df = df.dropna(axis=1)\n",
    "    return df\n",
    "    \n",
    "print('(a.)')\n",
    "print('shape after ignoring attribute(s) containing nan values..')\n",
    "for num, i in enumerate(all_datasets, 0):\n",
    "    print('dataset:',all_datasets_names[num], ignore_attribute(i).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b.)\n",
      "shape after replacing attribute(s) with mean/median of the entire dataset..\n",
      "\n",
      " >mean_cat. 0.0476 mean_num. 657.4725\n",
      " >median_cat. 0.0 median_num. 210.0\n",
      "dataset: rnd_2a_hi_lo shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_hi_lo shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      " >mean_cat. 0.0476 mean_num. 520.9677\n",
      " >median_cat. 0.0 median_num. 199.0\n",
      "dataset: rnd_2a_hi_hi shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_hi_hi shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      " >mean_cat. 0.0478 mean_num. 699.2705\n",
      " >median_cat. 0.0 median_num. 212.0\n",
      "dataset: rnd_2a_lo_lo shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_lo_lo shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      " >mean_cat. 0.0485 mean_num. 699.2705\n",
      " >median_cat. 0.0 median_num. 212.0\n",
      "dataset: rnd_2a_lo_hi shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_lo_hi shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      " >mean_cat. 0.0474 mean_num. 699.9277\n",
      " >median_cat. 0.0 median_num. 212.0\n",
      "dataset: rnd_2b_small shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2b_small shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      " >mean_cat. 0.0482 mean_num. 697.1868\n",
      " >median_cat. 0.0 median_num. 212.0\n",
      "dataset: rnd_2b_large shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2b_large shape (15120, 52) nan-count 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fill_custom(df, fill_with='mean'):\n",
    "    '''\n",
    "    3b\n",
    "    fill each nan with the mean/median of the whole dataset\n",
    "    - note we only differentiate between categorical and numerical feartures for mean max calculation\n",
    "    '''\n",
    "    if fill_with == 'median':\n",
    "        median_categorical = df[features_categorical].stack().median()\n",
    "        median_numerical = df[features_numerical].stack().median()\n",
    "\n",
    "        print(' >median_cat.', round(median_categorical,4), 'median_num.', round(median_numerical,4))\n",
    "        df[features_categorical] = df[features_categorical].fillna(median_categorical)\n",
    "        df[features_numerical] = df[features_numerical].fillna(median_numerical)\n",
    "    elif fill_with == 'mean':\n",
    "        mean_categorical = df[features_categorical].stack().mean()\n",
    "        mean_numerical = df[features_numerical].stack().mean()\n",
    "\n",
    "        print(' >mean_cat.', round(mean_categorical,4), 'mean_num.', round(mean_numerical,4))\n",
    "        df[features_categorical] = df[features_categorical].fillna(mean_categorical)\n",
    "        df[features_numerical] = df[features_numerical].fillna(mean_numerical)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print('(b.)')\n",
    "print('shape after replacing attribute(s) with mean/median of the entire dataset..\\n')\n",
    "for num, i in enumerate(all_datasets, 0):\n",
    "    tmp_mean = fill_custom(i.copy(), 'mean')\n",
    "    tmp_median = fill_custom(i.copy(), 'median')\n",
    "    print('dataset:',all_datasets_names[num], 'shape', tmp_mean.shape, 'nan-count', tmp_mean.isna().sum().sum())\n",
    "    print('dataset:',all_datasets_names[num], 'shape', tmp_median.shape, 'nan-count', tmp_median.isna().sum().sum())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(c.)\n",
      "shape after replacing attribute(s) with the feature respective mena/median containing nan values..\n",
      "dataset: rnd_2a_hi_lo shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_hi_lo shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      "dataset: rnd_2a_hi_hi shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_hi_hi shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      "dataset: rnd_2a_lo_lo shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_lo_lo shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      "dataset: rnd_2a_lo_hi shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2a_lo_hi shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      "dataset: rnd_2b_small shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2b_small shape (15120, 52) nan-count 0\n",
      "\n",
      "\n",
      "dataset: rnd_2b_large shape (15120, 52) nan-count 0\n",
      "dataset: rnd_2b_large shape (15120, 52) nan-count 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''replace with respective column mean/median'''\n",
    "\n",
    "def fill_attribute(df, fill_with='mean'):\n",
    "    if fill_with == 'mean':\n",
    "        df = df.fillna(df.mean())\n",
    "    elif fill_with == 'median':\n",
    "        df = df.fillna(df.median())\n",
    "    return df\n",
    "        \n",
    "        \n",
    "print('(c.)')\n",
    "print('shape after replacing attribute(s) with the feature respective mena/median containing nan values..')\n",
    "for num, i in enumerate(all_datasets, 0):\n",
    "    tmp_mean = fill_attribute(i, 'mean')\n",
    "    tmp_median = fill_attribute(i, 'median')\n",
    "    print('dataset:',all_datasets_names[num], 'shape', tmp_mean.shape, 'nan-count', tmp_mean.isna().sum().sum())\n",
    "    print('dataset:',all_datasets_names[num], 'shape', tmp_median.shape, 'nan-count', tmp_median.isna().sum().sum())\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
